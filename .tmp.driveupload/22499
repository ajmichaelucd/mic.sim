{
    "type": [
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        2,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2
    ],
    "data": [
        "+ ",
        "               dist=\"lognormal\",",
        "+ ",
        "               n = 2,",
        "+ ",
        "               cluster=NULL,",
        "+ ",
        "               classify=\"EM\",",
        "+ ",
        "               maxiter=10000, tol=1e-6)",
        "> ",
        "#d is the censoring indicator (0=right censored, 1=event at time,",
        "> ",
        "# 2=left censored, 3=interval censored)",
        "> ",
        "#wt are the weights for the observations",
        "> ",
        "#dist: either the \"weibull\", \"lognormal\", or \"gaussian\" distribution",
        "> ",
        "#n is the number of components",
        "> ",
        "#cluster: start with random initialization of posterior probabilities (=NULL), or",
        "> ",
        "# a matrix with n columns of initial posterior probabilities for the observations",
        "> ",
        "#classify: \"EM\", \"CEM\", or \"SEM\" strategy",
        "> ",
        "#maxiter is the maximum number of iterations",
        "> ",
        "#tol is the convergence criterion",
        "> ",
        "gmm_int_cen$components",
        "            mu     sigma\n[1,] -2.100862 0.7182039\n[2,]  2.098843 0.6973819\n",
        "> ",
        "`E[X|T,C]` = function(t, c)",
        "+ ",
        "{",
        "+ ",
        "  case_when(",
        "+ ",
        "    c == \"1\" ~ -2 + 0 * t,",
        "+ ",
        "    c == \"2\" ~ 2 + 0 * t,",
        "+ ",
        "    TRUE ~ NaN",
        "+ ",
        "  )",
        "+ ",
        "}",
        "> ",
        "t_dist1 = function(n){runif(n, min = 0, max = 1)}",
        "> ",
        "sd_vector = c(\"1\" = 1, \"2\" = 1)",
        "> ",
        "low_con = 2^-4",
        "> ",
        "high_con = 2^4",
        "> ",
        "##Covariate inputs--------------------",
        "> ",
        "covariate_effect_vector <- c(0 #0 at start is intercept, then add in the desired coefficients for the covariates",
        "+ ",
        ")",
        "> ",
        "covariate_list <-",
        "+ ",
        "  NULL",
        "> ",
        "covariate_names <- NULL",
        "> ",
        "data.sim <- simulate_mics(",
        "+ ",
        "  n = n,",
        "+ ",
        "  t_dist = t_dist1,",
        "+ ",
        "  pi = pi1,",
        "+ ",
        "  `E[X|T,C]` = `E[X|T,C]`,",
        "+ ",
        "  sd_vector = sd_vector,",
        "+ ",
        "  covariate_list = covariate_list,",
        "+ ",
        "  covariate_effect_vector = covariate_effect_vector,",
        "+ ",
        "  low_con = low_con,",
        "+ ",
        "  high_con = high_con)",
        "> ",
        "hist(data.sim$observed_value)",
        "> ",
        "table(data.sim$indicator == 2)",
        "\nFALSE  TRUE \n 1975    25 \n",
        "> ",
        "table(data.sim$left_bound)",
        "\n     0 0.0625  0.125   0.25    0.5      1      2      4      8     16 \n    25    152    411    445    172    129    248    277    123     18 \n",
        "> ",
        "table(ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ))",
        "\n0.0625  0.125   0.25    0.5      1      2      4      8     16 \n   177    411    445    172    129    248    277    123     18 \n",
        "> ",
        "gmm_int_cen <- mixcensoredInt(y1 = ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ),  #format would be wrong for this, need a conversion factor if using this notation",
        "+ ",
        "               y2 = data.sim$right_bound,",
        "+ ",
        "               d = data.sim$indicator,",
        "+ ",
        "               wt=rep(1, length(data.sim$observed_value)),",
        "+ ",
        "               dist=\"lognormal\",",
        "+ ",
        "               n = 2,",
        "+ ",
        "               cluster=NULL,",
        "+ ",
        "               classify=\"EM\",",
        "+ ",
        "               maxiter=10000, tol=1e-6)",
        "> ",
        "#d is the censoring indicator (0=right censored, 1=event at time,",
        "> ",
        "# 2=left censored, 3=interval censored)",
        "> ",
        "#wt are the weights for the observations",
        "> ",
        "#dist: either the \"weibull\", \"lognormal\", or \"gaussian\" distribution",
        "> ",
        "#n is the number of components",
        "> ",
        "#cluster: start with random initialization of posterior probabilities (=NULL), or",
        "> ",
        "# a matrix with n columns of initial posterior probabilities for the observations",
        "> ",
        "#classify: \"EM\", \"CEM\", or \"SEM\" strategy",
        "> ",
        "#maxiter is the maximum number of iterations",
        "> ",
        "#tol is the convergence criterion",
        "> ",
        "gmm_int_cen$components",
        "            mu     sigma\n[1,] -1.367911 0.6746278\n[2,]  1.434411 0.6947823\n",
        "> ",
        "gmm_int_cen <- mixcensoredInt(y1 = data.sim$left_bound ),  #format would be wrong for this, need a conversion factor if using this notation",
        "Error: unexpected ',' in \"gmm_int_cen <- mixcensoredInt(y1 = data.sim$left_bound ),\"\n",
        "> ",
        "                              y2 = data.sim$right_bound,",
        "Error: unexpected ',' in \"                              y2 = data.sim$right_bound,\"\n",
        "> ",
        "                              d = data.sim$indicator,",
        "Error: unexpected ',' in \"                              d = data.sim$indicator,\"\n",
        "> ",
        "                              wt=rep(1, length(data.sim$observed_value)),",
        "Error: unexpected ',' in \"                              wt=rep(1, length(data.sim$observed_value)),\"\n",
        "> ",
        "                              dist=\"lognormal\",",
        "Error: unexpected ',' in \"                              dist=\"lognormal\",\"\n",
        "> ",
        "                              n = 2,",
        "Error: unexpected ',' in \"                              n = 2,\"\n",
        "> ",
        "                              cluster=NULL,",
        "Error: unexpected ',' in \"                              cluster=NULL,\"\n",
        "> ",
        "                              classify=\"EM\",",
        "Error: unexpected ',' in \"                              classify=\"EM\",\"\n",
        "> ",
        "                              maxiter=10000, tol=1e-6)",
        "Error: unexpected ',' in \"                              maxiter=10000,\"\n",
        "> ",
        "gmm_int_cen <- mixcensoredInt(y1 = data.sim$left_bound ,  #format would be wrong for this, need a conversion factor if using this notation",
        "+ ",
        "                              y2 = data.sim$right_bound,",
        "+ ",
        "                              d = data.sim$indicator,",
        "+ ",
        "                              wt=rep(1, length(data.sim$observed_value)),",
        "+ ",
        "                              dist=\"lognormal\",",
        "+ ",
        "                              n = 2,",
        "+ ",
        "                              cluster=NULL,",
        "+ ",
        "                              classify=\"EM\",",
        "+ ",
        "                              maxiter=10000, tol=1e-6)",
        "Error in survreg(Surv(y1, y2, d, type = \"interval\") ~ 1, weights = wtp,  : \n  Invalid survival times for this distribution\n",
        "Called from: survreg(Surv(y1, y2, d, type = \"interval\") ~ 1, weights = wtp, \n    dist = dist)\n",
        "Browse[1]> ",
        "plot(x = gmm_int_cen$likelihood_documentation_gmm[,1], y= gmm_int_cen$likelihood_documentation_gmm[,2], type = \"l\")",
        "Browse[1]> ",
        "lines(x = likelihood_documentation[,1], y = likelihood_documentation[,2])",
        "Error during wrapup: ",
        "object 'likelihood_documentation' not found\n",
        "Error: no more error handlers available (recursive errors?); invoking 'abort' restart\n",
        "Browse[1]> ",
        "",
        "> ",
        "gmm_int_cen <- mixcensoredInt(y1 = ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ),  #format would be wrong for this, need a conversion factor if using this notation",
        "+ ",
        "               y2 = data.sim$right_bound,",
        "+ ",
        "               d = data.sim$indicator,",
        "+ ",
        "               wt=rep(1, length(data.sim$observed_value)),",
        "+ ",
        "               dist=\"lognormal\",",
        "+ ",
        "               n = 2,",
        "+ ",
        "               cluster=NULL,",
        "+ ",
        "               classify=\"EM\",",
        "+ ",
        "               maxiter=10000, tol=1e-6)",
        "> ",
        "#d is the censoring indicator (0=right censored, 1=event at time,",
        "> ",
        "# 2=left censored, 3=interval censored)",
        "> ",
        "#wt are the weights for the observations",
        "> ",
        "#dist: either the \"weibull\", \"lognormal\", or \"gaussian\" distribution",
        "> ",
        "#n is the number of components",
        "> ",
        "#cluster: start with random initialization of posterior probabilities (=NULL), or",
        "> ",
        "# a matrix with n columns of initial posterior probabilities for the observations",
        "> ",
        "#classify: \"EM\", \"CEM\", or \"SEM\" strategy",
        "> ",
        "#maxiter is the maximum number of iterations",
        "> ",
        "#tol is the convergence criterion",
        "> ",
        "gmm_int_cen$components",
        "             mu    sigma\n[1,] -0.2646294 1.544362\n[2,] -0.2830144 1.541995\n",
        "> ",
        "gmm_int_cen <- mixcensoredInt(y1 = ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ),  #format would be wrong for this, need a conversion factor if using this notation",
        "+ ",
        "               y2 = data.sim$right_bound,",
        "+ ",
        "               d = data.sim$indicator,",
        "+ ",
        "               wt=rep(1, length(data.sim$observed_value)),",
        "+ ",
        "               dist=\"lognormal\",",
        "+ ",
        "               n = 2,",
        "+ ",
        "               cluster=NULL,",
        "+ ",
        "               classify=\"EM\",",
        "+ ",
        "               maxiter=10000, tol=1e-6)",
        "> ",
        "#d is the censoring indicator (0=right censored, 1=event at time,",
        "> ",
        "# 2=left censored, 3=interval censored)",
        "> ",
        "#wt are the weights for the observations",
        "> ",
        "#dist: either the \"weibull\", \"lognormal\", or \"gaussian\" distribution",
        "> ",
        "#n is the number of components",
        "> ",
        "#cluster: start with random initialization of posterior probabilities (=NULL), or",
        "> ",
        "# a matrix with n columns of initial posterior probabilities for the observations",
        "> ",
        "#classify: \"EM\", \"CEM\", or \"SEM\" strategy",
        "> ",
        "#maxiter is the maximum number of iterations",
        "> ",
        "#tol is the convergence criterion",
        "> ",
        "gmm_int_cen$components",
        "             mu    sigma\n[1,] -0.3123482 1.537399\n[2,] -0.2357960 1.547973\n",
        "> ",
        "plot(x = gmm_int_cen$likelihood_documentation_gmm[,1], y= gmm_int_cen$likelihood_documentation_gmm[,2], type = \"l\")",
        "> ",
        "lines(x = likelihood_documentation[,1], y = likelihood_documentation[,2])",
        "Error in lines(x = likelihood_documentation[, 1], y = likelihood_documentation[,  : \n  object 'likelihood_documentation' not found\n",
        "> ",
        "#d is the censoring indicator (0=right censored, 1=event at time,",
        "> ",
        "# 2=left censored, 3=interval censored)",
        "> ",
        "#wt are the weights for the observations",
        "> ",
        "#dist: either the \"weibull\", \"lognormal\", or \"gaussian\" distribution",
        "> ",
        "#n is the number of components",
        "> ",
        "#cluster: start with random initialization of posterior probabilities (=NULL), or",
        "> ",
        "# a matrix with n columns of initial posterior probabilities for the observations",
        "> ",
        "#classify: \"EM\", \"CEM\", or \"SEM\" strategy",
        "> ",
        "#maxiter is the maximum number of iterations",
        "> ",
        "#tol is the convergence criterion",
        "> ",
        "gmm_int_cen",
        "$components\n             mu    sigma\n[1,] -0.3123482 1.537399\n[2,] -0.2357960 1.547973\n\n$prior\n[1] 0.4969141 0.5030859\n\n$loglik\n[1] -5801.351\n\n$AIC\n[1] 11612.7\n\n$BIC\n[1] 11640.71\n\n$strategy\n[1] \"EM\"\n\n$distribution\n[1] \"lognormal\"\n\n$iterations\n[1] 2\n\n$standardError\n             mu log(sigma)\n[1,] 0.04924134 0.02317785\n[2,] 0.04926742 0.02302410\n\n$posterior\n             [,1]      [,2]\n   [1,] 0.4870102 0.5129898\n   [2,] 0.4799333 0.5200667\n   [3,] 0.4870102 0.5129898\n   [4,] 0.4799333 0.5200667\n   [5,] 0.4991677",
        " 0.5008323\n   [6,] 0.4799333 0.5200667\n   [7,] 0.4991677 0.5008323\n   [8,] 0.5042443 0.4957557\n   [9,] 0.4721958 0.5278042\n  [10,] 0.5086517 0.4913483\n  [11,] 0.4870102 0.5129898\n  [12,] 0.5123897 0.4876103\n  [13,] 0.5086517 0.4913483\n  [14,] 0.4870102 0.5129898\n  [15,] 0.5042443 0.4957557\n  [16,] 0.5042443 0.4957557\n  [17,] 0.5042443 0.4957557\n  [18,] 0.4799333 0.5200667\n  [19,] 0.4934225 0.5065775\n  [20,] 0.4799333 0.5200667\n  [21,] 0.4870102 0.5129898\n  [22,] 0.5042443 0.4957557\n  [23,] 0.4799333 0.5200667",
        "\n  [24,] 0.5042443 0.4957557\n  [25,] 0.4721958 0.5278042\n  [26,] 0.5042443 0.4957557\n  [27,] 0.5086517 0.4913483\n  [28,] 0.4870102 0.5129898\n  [29,] 0.5086517 0.4913483\n  [30,] 0.5042443 0.4957557\n  [31,] 0.5086517 0.4913483\n  [32,] 0.4991677 0.5008323\n  [33,] 0.5086517 0.4913483\n  [34,] 0.5086517 0.4913483\n  [35,] 0.4991677 0.5008323\n  [36,] 0.5042443 0.4957557\n  [37,] 0.5086517 0.4913483\n  [38,] 0.4721958 0.5278042\n  [39,] 0.5042443 0.4957557\n  [40,] 0.5042443 0.4957557\n  [41,] 0.5086517 0.4913483\n  [42,]",
        " 0.4870102 0.5129898\n  [43,] 0.4991677 0.5008323\n  [44,] 0.4870102 0.5129898\n  [45,] 0.4721958 0.5278042\n  [46,] 0.4799333 0.5200667\n  [47,] 0.4991677 0.5008323\n  [48,] 0.4799333 0.5200667\n  [49,] 0.5042443 0.4957557\n  [50,] 0.5042443 0.4957557\n  [51,] 0.4934225 0.5065775\n  [52,] 0.4991677 0.5008323\n  [53,] 0.5123897 0.4876103\n  [54,] 0.4870102 0.5129898\n  [55,] 0.5086517 0.4913483\n  [56,] 0.4991677 0.5008323\n  [57,] 0.4934225 0.5065775\n  [58,] 0.4721958 0.5278042\n  [59,] 0.4721958 0.5278042\n  [60,] 0.4870102",
        " 0.5129898\n  [61,] 0.5086517 0.4913483\n  [62,] 0.4934225 0.5065775\n  [63,] 0.5042443 0.4957557\n  [64,] 0.4721958 0.5278042\n  [65,] 0.5042443 0.4957557\n  [66,] 0.4870102 0.5129898\n  [67,] 0.5042443 0.4957557\n  [68,] 0.5042443 0.4957557\n  [69,] 0.5086517 0.4913483\n  [70,] 0.4870102 0.5129898\n  [71,] 0.5042443 0.4957557\n  [72,] 0.4721958 0.5278042\n  [73,] 0.5086517 0.4913483\n  [74,] 0.4799333 0.5200667\n  [75,] 0.5086517 0.4913483\n  [76,] 0.5042443 0.4957557\n  [77,] 0.5086517 0.4913483\n  [78,] 0.5042443 0.4957557",
        "\n  [79,] 0.4870102 0.5129898\n  [80,] 0.4991677 0.5008323\n  [81,] 0.5042443 0.4957557\n  [82,] 0.5042443 0.4957557\n  [83,] 0.4721958 0.5278042\n  [84,] 0.5086517 0.4913483\n  [85,] 0.4799333 0.5200667\n  [86,] 0.4799333 0.5200667\n  [87,] 0.4870102 0.5129898\n  [88,] 0.4799333 0.5200667\n  [89,] 0.5086517 0.4913483\n  [90,] 0.4870102 0.5129898\n  [91,] 0.4721958 0.5278042\n  [92,] 0.4991677 0.5008323\n  [93,] 0.4721958 0.5278042\n  [94,] 0.5086517 0.4913483\n  [95,] 0.5086517 0.4913483\n  [96,] 0.4870102 0.5129898\n  [97,]",
        " 0.4991677 0.5008323\n  [98,] 0.5086517 0.4913483\n  [99,] 0.4870102 0.5129898\n [100,] 0.4721958 0.5278042\n [101,] 0.4991677 0.5008323\n [102,] 0.4721958 0.5278042\n [103,] 0.5042443 0.4957557\n [104,] 0.4721958 0.5278042\n [105,] 0.5086517 0.4913483\n [106,] 0.5086517 0.4913483\n [107,] 0.4799333 0.5200667\n [108,] 0.5086517 0.4913483\n [109,] 0.4870102 0.5129898\n [110,] 0.5123897 0.4876103\n [111,] 0.5086517 0.4913483\n [112,] 0.5042443 0.4957557\n [113,] 0.5042443 0.4957557\n [114,] 0.4934225 0.5065775\n [115,] 0.5042443",
        " 0.4957557\n [116,] 0.4799333 0.5200667\n [117,] 0.4870102 0.5129898\n [118,] 0.5123897 0.4876103\n [119,] 0.5042443 0.4957557\n [120,] 0.5123897 0.4876103\n [121,] 0.4991677 0.5008323\n [122,] 0.5123897 0.4876103\n [123,] 0.4870102 0.5129898\n [124,] 0.5086517 0.4913483\n [125,] 0.4870102 0.5129898\n [126,] 0.4799333 0.5200667\n [127,] 0.4598765 0.5401235\n [128,] 0.5086517 0.4913483\n [129,] 0.5086517 0.4913483\n [130,] 0.4991677 0.5008323\n [131,] 0.5042443 0.4957557\n [132,] 0.4870102 0.5129898\n [133,] 0.4799333 0.5200667",
        "\n [134,] 0.4870102 0.5129898\n [135,] 0.4934225 0.5065775\n [136,] 0.4799333 0.5200667\n [137,] 0.5086517 0.4913483\n [138,] 0.5123897 0.4876103\n [139,] 0.5086517 0.4913483\n [140,] 0.5042443 0.4957557\n [141,] 0.4870102 0.5129898\n [142,] 0.4934225 0.5065775\n [143,] 0.5123897 0.4876103\n [144,] 0.5042443 0.4957557\n [145,] 0.4598765 0.5401235\n [146,] 0.4991677 0.5008323\n [147,] 0.5042443 0.4957557\n [148,] 0.5123897 0.4876103\n [149,] 0.4870102 0.5129898\n [150,] 0.5086517 0.4913483\n [151,] 0.5042443 0.4957557\n [152,]",
        " 0.4870102 0.5129898\n [153,] 0.5042443 0.4957557\n [154,] 0.4934225 0.5065775\n [155,] 0.5086517 0.4913483\n [156,] 0.5042443 0.4957557\n [157,] 0.5042443 0.4957557\n [158,] 0.4799333 0.5200667\n [159,] 0.5086517 0.4913483\n [160,] 0.4799333 0.5200667\n [161,] 0.4799333 0.5200667\n [162,] 0.5042443 0.4957557\n [163,] 0.4870102 0.5129898\n [164,] 0.4870102 0.5129898\n [165,] 0.4991677 0.5008323\n [166,] 0.4991677 0.5008323\n [167,] 0.5086517 0.4913483\n [168,] 0.4721958 0.5278042\n [169,] 0.4870102 0.5129898\n [170,] 0.5086517",
        " 0.4913483\n [171,] 0.4870102 0.5129898\n [172,] 0.5086517 0.4913483\n [173,] 0.4991677 0.5008323\n [174,] 0.4799333 0.5200667\n [175,] 0.5086517 0.4913483\n [176,] 0.5042443 0.4957557\n [177,] 0.4870102 0.5129898\n [178,] 0.5042443 0.4957557\n [179,] 0.5042443 0.4957557\n [180,] 0.4799333 0.5200667\n [181,] 0.4598765 0.5401235\n [182,] 0.4799333 0.5200667\n [183,] 0.4721958 0.5278042\n [184,] 0.4721958 0.5278042\n [185,] 0.4799333 0.5200667\n [186,] 0.5042443 0.4957557\n [187,] 0.4991677 0.5008323\n [188,] 0.5042443 0.4957557",
        "\n [189,] 0.5086517 0.4913483\n [190,] 0.5086517 0.4913483\n [191,] 0.5123897 0.4876103\n [192,] 0.4934225 0.5065775\n [193,] 0.4799333 0.5200667\n [194,] 0.5042443 0.4957557\n [195,] 0.5123897 0.4876103\n [196,] 0.4870102 0.5129898\n [197,] 0.4799333 0.5200667\n [198,] 0.4799333 0.5200667\n [199,] 0.5123897 0.4876103\n [200,] 0.5123897 0.4876103\n [201,] 0.4934225 0.5065775\n [202,] 0.4799333 0.5200667\n [203,] 0.4991677 0.5008323\n [204,] 0.4870102 0.5129898\n [205,] 0.4799333 0.5200667\n [206,] 0.5042443 0.4957557\n [207,]",
        " 0.5086517 0.4913483\n [208,] 0.5086517 0.4913483\n [209,] 0.4934225 0.5065775\n [210,] 0.4991677 0.5008323\n [211,] 0.5086517 0.4913483\n [212,] 0.4934225 0.5065775\n [213,] 0.5086517 0.4913483\n [214,] 0.4991677 0.5008323\n [215,] 0.5042443 0.4957557\n [216,] 0.5123897 0.4876103\n [217,] 0.5042443 0.4957557\n [218,] 0.4934225 0.5065775\n [219,] 0.5086517 0.4913483\n [220,] 0.5165629 0.4834371\n [221,] 0.5042443 0.4957557\n [222,] 0.4991677 0.5008323\n [223,] 0.5086517 0.4913483\n [224,] 0.5042443 0.4957557\n [225,] 0.5086517",
        " 0.4913483\n [226,] 0.4799333 0.5200667\n [227,] 0.5123897 0.4876103\n [228,] 0.4799333 0.5200667\n [229,] 0.4991677 0.5008323\n [230,] 0.5042443 0.4957557\n [231,] 0.4721958 0.5278042\n [232,] 0.4934225 0.5065775\n [233,] 0.5042443 0.4957557\n [234,] 0.5086517 0.4913483\n [235,] 0.4934225 0.5065775\n [236,] 0.4934225 0.5065775\n [237,] 0.4799333 0.5200667\n [238,] 0.4934225 0.5065775\n [239,] 0.4799333 0.5200667\n [240,] 0.5042443 0.4957557\n [241,] 0.5042443 0.4957557\n [242,] 0.4870102 0.5129898\n [243,] 0.5086517 0.4913483",
        "\n [244,] 0.4934225 0.5065775\n [245,] 0.4991677 0.5008323\n [246,] 0.5086517 0.4913483\n [247,] 0.5086517 0.4913483\n [248,] 0.4870102 0.5129898\n [249,] 0.5086517 0.4913483\n [250,] 0.5086517 0.4913483\n [251,] 0.5042443 0.4957557\n [252,] 0.5042443 0.4957557\n [253,] 0.5086517 0.4913483\n [254,] 0.4870102 0.5129898\n [255,] 0.4991677 0.5008323\n [256,] 0.5042443 0.4957557\n [257,] 0.5042443 0.4957557\n [258,] 0.4799333 0.5200667\n [259,] 0.5086517 0.4913483\n [260,] 0.5123897 0.4876103\n [261,] 0.5165629 0.4834371\n [262,]",
        " 0.5042443 0.4957557\n [263,] 0.5042443 0.4957557\n [264,] 0.5123897 0.4876103\n [265,] 0.5123897 0.4876103\n [266,] 0.4799333 0.5200667\n [267,] 0.5042443 0.4957557\n [268,] 0.5042443 0.4957557\n [269,] 0.5042443 0.4957557\n [270,] 0.5042443 0.4957557\n [271,] 0.4934225 0.5065775\n [272,] 0.5042443 0.4957557\n [273,] 0.4799333 0.5200667\n [274,] 0.4799333 0.5200667\n [275,] 0.5123897 0.4876103\n [276,] 0.5086517 0.4913483\n [277,] 0.5123897 0.4876103\n [278,] 0.4721958 0.5278042\n [279,] 0.5042443 0.4957557\n [280,] 0.5086517",
        " 0.4913483\n [281,] 0.4799333 0.5200667\n [282,] 0.5086517 0.4913483\n [283,] 0.5042443 0.4957557\n [284,] 0.5042443 0.4957557\n [285,] 0.5086517 0.4913483\n [286,] 0.5086517 0.4913483\n [287,] 0.5086517 0.4913483\n [288,] 0.4799333 0.5200667\n [289,] 0.4870102 0.5129898\n [290,] 0.4991677 0.5008323\n [291,] 0.4799333 0.5200667\n [292,] 0.5042443 0.4957557\n [293,] 0.4870102 0.5129898\n [294,] 0.4870102 0.5129898\n [295,] 0.4870102 0.5129898\n [296,] 0.5086517 0.4913483\n [297,] 0.4721958 0.5278042\n [298,] 0.5086517 0.4913483",
        "\n [299,] 0.4799333 0.5200667\n [300,] 0.4991677 0.5008323\n [301,] 0.4870102 0.5129898\n [302,] 0.5042443 0.4957557\n [303,] 0.5086517 0.4913483\n [304,] 0.4799333 0.5200667\n [305,] 0.5086517 0.4913483\n [306,] 0.4721958 0.5278042\n [307,] 0.4991677 0.5008323\n [308,] 0.4721958 0.5278042\n [309,] 0.5042443 0.4957557\n [310,] 0.4870102 0.5129898\n [311,] 0.4934225 0.5065775\n [312,] 0.5086517 0.4913483\n [313,] 0.5086517 0.4913483\n [314,] 0.5086517 0.4913483\n [315,] 0.5042443 0.4957557\n [316,] 0.4934225 0.5065775\n [317,]",
        " 0.4870102 0.5129898\n [318,] 0.5042443 0.4957557\n [319,] 0.4870102 0.5129898\n [320,] 0.5123897 0.4876103\n [321,] 0.4721958 0.5278042\n [322,] 0.4870102 0.5129898\n [323,] 0.5123897 0.4876103\n [324,] 0.5086517 0.4913483\n [325,] 0.4870102 0.5129898\n [326,] 0.4799333 0.5200667\n [327,] 0.4799333 0.5200667\n [328,] 0.4799333 0.5200667\n [329,] 0.4870102 0.5129898\n [330,] 0.4799333 0.5200667\n [331,] 0.5086517 0.4913483\n [332,] 0.5086517 0.4913483\n [333,] 0.4799333 0.5200667\n [334,] 0.5042443 0.4957557\n [335,] 0.5123897",
        " 0.4876103\n [336,] 0.4991677 0.5008323\n [337,] 0.5123897 0.4876103\n [338,] 0.5086517 0.4913483\n [339,] 0.4721958 0.5278042\n [340,] 0.4934225 0.5065775\n [341,] 0.4870102 0.5129898\n [342,] 0.4991677 0.5008323\n [343,] 0.5086517 0.4913483\n [344,] 0.5086517 0.4913483\n [345,] 0.5042443 0.4957557\n [346,] 0.4870102 0.5129898\n [347,] 0.5165629 0.4834371\n [348,] 0.5086517 0.4913483\n [349,] 0.5042443 0.4957557\n [350,] 0.5086517 0.4913483\n [351,] 0.4799333 0.5200667\n [352,] 0.4934225 0.5065775\n [353,] 0.4721958 0.5278042",
        "\n [354,] 0.5123897 0.4876103\n [355,] 0.5086517 0.4913483\n [356,] 0.5086517 0.4913483\n [357,] 0.5086517 0.4913483\n [358,] 0.4991677 0.5008323\n [359,] 0.5086517 0.4913483\n [360,] 0.5086517 0.4913483\n [361,] 0.4799333 0.5200667\n [362,] 0.4870102 0.5129898\n [363,] 0.5042443 0.4957557\n [364,] 0.5086517 0.4913483\n [365,] 0.5042443 0.4957557\n [366,] 0.4991677 0.5008323\n [367,] 0.5042443 0.4957557\n [368,] 0.4991677 0.5008323\n [369,] 0.5086517 0.4913483\n [370,] 0.5042443 0.4957557\n [371,] 0.5123897 0.4876103\n [372,]",
        " 0.5042443 0.4957557\n [373,] 0.4870102 0.5129898\n [374,] 0.4991677 0.5008323\n [375,] 0.4870102 0.5129898\n [376,] 0.5042443 0.4957557\n [377,] 0.4934225 0.5065775\n [378,] 0.4991677 0.5008323\n [379,] 0.4799333 0.5200667\n [380,] 0.4991677 0.5008323\n [381,] 0.5123897 0.4876103\n [382,] 0.5086517 0.4913483\n [383,] 0.5086517 0.4913483\n [384,] 0.5086517 0.4913483\n [385,] 0.5123897 0.4876103\n [386,] 0.5042443 0.4957557\n [387,] 0.5042443 0.4957557\n [388,] 0.5123897 0.4876103\n [389,] 0.5042443 0.4957557\n [390,] 0.5086517",
        " 0.4913483\n [391,] 0.4799333 0.5200667\n [392,] 0.5086517 0.4913483\n [393,] 0.4799333 0.5200667\n [394,] 0.4934225 0.5065775\n [395,] 0.5086517 0.4913483\n [396,] 0.4991677 0.5008323\n [397,] 0.5042443 0.4957557\n [398,] 0.4799333 0.5200667\n [399,] 0.4799333 0.5200667\n [400,] 0.5042443 0.4957557\n [401,] 0.4870102 0.5129898\n [402,] 0.4799333 0.5200667\n [403,] 0.5042443 0.4957557\n [404,] 0.4934225 0.5065775\n [405,] 0.4934225 0.5065775\n [406,] 0.4799333 0.5200667\n [407,] 0.5123897 0.4876103\n [408,] 0.5123897 0.4876103",
        "\n [409,] 0.5042443 0.4957557\n [410,] 0.5086517 0.4913483\n [411,] 0.5086517 0.4913483\n [412,] 0.5123897 0.4876103\n [413,] 0.4991677 0.5008323\n [414,] 0.4799333 0.5200667\n [415,] 0.4598765 0.5401235\n [416,] 0.4991677 0.5008323\n [417,] 0.5042443 0.4957557\n [418,] 0.4799333 0.5200667\n [419,] 0.5042443 0.4957557\n [420,] 0.4991677 0.5008323\n [421,] 0.5123897 0.4876103\n [422,] 0.5042443 0.4957557\n [423,] 0.4934225 0.5065775\n [424,] 0.4870102 0.5129898\n [425,] 0.5086517 0.4913483\n [426,] 0.4721958 0.5278042\n [427,]",
        " 0.5042443 0.4957557\n [428,] 0.5086517 0.4913483\n [429,] 0.5165629 0.4834371\n [430,] 0.4870102 0.5129898\n [431,] 0.4870102 0.5129898\n [432,] 0.5042443 0.4957557\n [433,] 0.4799333 0.5200667\n [434,] 0.4870102 0.5129898\n [435,] 0.4991677 0.5008323\n [436,] 0.4934225 0.5065775\n [437,] 0.4799333 0.5200667\n [438,] 0.5086517 0.4913483\n [439,] 0.5042443 0.4957557\n [440,] 0.4934225 0.5065775\n [441,] 0.4721958 0.5278042\n [442,] 0.4721958 0.5278042\n [443,] 0.4799333 0.5200667\n [444,] 0.5165629 0.4834371\n [445,] 0.4870102",
        " 0.5129898\n [446,] 0.5086517 0.4913483\n [447,] 0.4934225 0.5065775\n [448,] 0.4799333 0.5200667\n [449,] 0.5042443 0.4957557\n [450,] 0.5042443 0.4957557\n [451,] 0.5042443 0.4957557\n [452,] 0.5086517 0.4913483\n [453,] 0.4799333 0.5200667\n [454,] 0.4934225 0.5065775\n [455,] 0.4934225 0.5065775\n [456,] 0.4991677 0.5008323\n [457,] 0.5086517 0.4913483\n [458,] 0.5042443 0.4957557\n [459,] 0.5086517 0.4913483\n [460,] 0.4991677 0.5008323\n [461,] 0.5042443 0.4957557\n [462,] 0.5086517 0.4913483\n [463,] 0.4991677 0.5008323",
        "\n [464,] 0.5086517 0.4913483\n [465,] 0.4721958 0.5278042\n [466,] 0.4934225 0.5065775\n [467,] 0.4934225 0.5065775\n [468,] 0.4934225 0.5065775\n [469,] 0.5042443 0.4957557\n [470,] 0.5086517 0.4913483\n [471,] 0.5042443 0.4957557\n [472,] 0.5042443 0.4957557\n [473,] 0.5042443 0.4957557\n [474,] 0.4799333 0.5200667\n [475,] 0.4870102 0.5129898\n [476,] 0.4799333 0.5200667\n [477,] 0.5042443 0.4957557\n [478,] 0.5042443 0.4957557\n [479,] 0.5086517 0.4913483\n [480,] 0.4799333 0.5200667\n [481,] 0.5042443 0.4957557\n [482,]",
        " 0.5123897 0.4876103\n [483,] 0.5123897 0.4876103\n [484,] 0.4870102 0.5129898\n [485,] 0.5123897 0.4876103\n [486,] 0.5086517 0.4913483\n [487,] 0.4870102 0.5129898\n [488,] 0.5086517 0.4913483\n [489,] 0.4934225 0.5065775\n [490,] 0.4721958 0.5278042\n [491,] 0.5042443 0.4957557\n [492,] 0.5123897 0.4876103\n [493,] 0.4799333 0.5200667\n [494,] 0.5086517 0.4913483\n [495,] 0.5042443 0.4957557\n [496,] 0.4934225 0.5065775\n [497,] 0.4870102 0.5129898\n [498,] 0.4799333 0.5200667\n [499,] 0.5086517 0.4913483\n [500,] 0.4870102",
        " 0.5129898\n [ reached getOption(\"max.print\") -- omitted 1500 rows ]\n\n$likelihood_documentation_gmm\n          [,1]      [,2]\n    [1,]     1 -5801.353\n    [2,]     2 -5801.351\n    [3,]     3        NA\n    [4,]     4        NA\n    [5,]     5        NA\n    [6,]     6        NA\n    [7,]     7        NA\n    [8,]     8        NA\n    [9,]     9        NA\n   [10,]    10        NA\n   [11,]    11        NA\n   [12,]    12        NA\n   [13,]    13        NA\n   [14,]    14        NA\n   [15,]    15        NA\n   [16,]    16",
        "        NA\n   [17,]    17        NA\n   [18,]    18        NA\n   [19,]    19        NA\n   [20,]    20        NA\n   [21,]    21        NA\n   [22,]    22        NA\n   [23,]    23        NA\n   [24,]    24        NA\n   [25,]    25        NA\n   [26,]    26        NA\n   [27,]    27        NA\n   [28,]    28        NA\n   [29,]    29        NA\n   [30,]    30        NA\n   [31,]    31        NA\n   [32,]    32        NA\n   [33,]    33        NA\n   [34,]    34        NA\n   [35,]    35        NA\n   [36,]    36        NA\n   [37,]",
        "    37        NA\n   [38,]    38        NA\n   [39,]    39        NA\n   [40,]    40        NA\n   [41,]    41        NA\n   [42,]    42        NA\n   [43,]    43        NA\n   [44,]    44        NA\n   [45,]    45        NA\n   [46,]    46        NA\n   [47,]    47        NA\n   [48,]    48        NA\n   [49,]    49        NA\n   [50,]    50        NA\n   [51,]    51        NA\n   [52,]    52        NA\n   [53,]    53        NA\n   [54,]    54        NA\n   [55,]    55        NA\n   [56,]    56        NA\n   [57,]    57        NA",
        "\n   [58,]    58        NA\n   [59,]    59        NA\n   [60,]    60        NA\n   [61,]    61        NA\n   [62,]    62        NA\n   [63,]    63        NA\n   [64,]    64        NA\n   [65,]    65        NA\n   [66,]    66        NA\n   [67,]    67        NA\n   [68,]    68        NA\n   [69,]    69        NA\n   [70,]    70        NA\n   [71,]    71        NA\n   [72,]    72        NA\n   [73,]    73        NA\n   [74,]    74        NA\n   [75,]    75        NA\n   [76,]    76        NA\n   [77,]    77        NA\n   [78,]    78",
        "        NA\n   [79,]    79        NA\n   [80,]    80        NA\n   [81,]    81        NA\n   [82,]    82        NA\n   [83,]    83        NA\n   [84,]    84        NA\n   [85,]    85        NA\n   [86,]    86        NA\n   [87,]    87        NA\n   [88,]    88        NA\n   [89,]    89        NA\n   [90,]    90        NA\n   [91,]    91        NA\n   [92,]    92        NA\n   [93,]    93        NA\n   [94,]    94        NA\n   [95,]    95        NA\n   [96,]    96        NA\n   [97,]    97        NA\n   [98,]    98        NA\n   [99,]",
        "    99        NA\n  [100,]   100        NA\n  [101,]   101        NA\n  [102,]   102        NA\n  [103,]   103        NA\n  [104,]   104        NA\n  [105,]   105        NA\n  [106,]   106        NA\n  [107,]   107        NA\n  [108,]   108        NA\n  [109,]   109        NA\n  [110,]   110        NA\n  [111,]   111        NA\n  [112,]   112        NA\n  [113,]   113        NA\n  [114,]   114        NA\n  [115,]   115        NA\n  [116,]   116        NA\n  [117,]   117        NA\n  [118,]   118        NA\n  [119,]   119        NA",
        "\n  [120,]   120        NA\n  [121,]   121        NA\n  [122,]   122        NA\n  [123,]   123        NA\n  [124,]   124        NA\n  [125,]   125        NA\n  [126,]   126        NA\n  [127,]   127        NA\n  [128,]   128        NA\n  [129,]   129        NA\n  [130,]   130        NA\n  [131,]   131        NA\n  [132,]   132        NA\n  [133,]   133        NA\n  [134,]   134        NA\n  [135,]   135        NA\n  [136,]   136        NA\n  [137,]   137        NA\n  [138,]   138        NA\n  [139,]   139        NA\n  [140,]   140",
        "        NA\n  [141,]   141        NA\n  [142,]   142        NA\n  [143,]   143        NA\n  [144,]   144        NA\n  [145,]   145        NA\n  [146,]   146        NA\n  [147,]   147        NA\n  [148,]   148        NA\n  [149,]   149        NA\n  [150,]   150        NA\n  [151,]   151        NA\n  [152,]   152        NA\n  [153,]   153        NA\n  [154,]   154        NA\n  [155,]   155        NA\n  [156,]   156        NA\n  [157,]   157        NA\n  [158,]   158        NA\n  [159,]   159        NA\n  [160,]   160        NA\n  [161,]",
        "   161        NA\n  [162,]   162        NA\n  [163,]   163        NA\n  [164,]   164        NA\n  [165,]   165        NA\n  [166,]   166        NA\n  [167,]   167        NA\n  [168,]   168        NA\n  [169,]   169        NA\n  [170,]   170        NA\n  [171,]   171        NA\n  [172,]   172        NA\n  [173,]   173        NA\n  [174,]   174        NA\n  [175,]   175        NA\n  [176,]   176        NA\n  [177,]   177        NA\n  [178,]   178        NA\n  [179,]   179        NA\n  [180,]   180        NA\n  [181,]   181        NA",
        "\n  [182,]   182        NA\n  [183,]   183        NA\n  [184,]   184        NA\n  [185,]   185        NA\n  [186,]   186        NA\n  [187,]   187        NA\n  [188,]   188        NA\n  [189,]   189        NA\n  [190,]   190        NA\n  [191,]   191        NA\n  [192,]   192        NA\n  [193,]   193        NA\n  [194,]   194        NA\n  [195,]   195        NA\n  [196,]   196        NA\n  [197,]   197        NA\n  [198,]   198        NA\n  [199,]   199        NA\n  [200,]   200        NA\n  [201,]   201        NA\n  [202,]   202",
        "        NA\n  [203,]   203        NA\n  [204,]   204        NA\n  [205,]   205        NA\n  [206,]   206        NA\n  [207,]   207        NA\n  [208,]   208        NA\n  [209,]   209        NA\n  [210,]   210        NA\n  [211,]   211        NA\n  [212,]   212        NA\n  [213,]   213        NA\n  [214,]   214        NA\n  [215,]   215        NA\n  [216,]   216        NA\n  [217,]   217        NA\n  [218,]   218        NA\n  [219,]   219        NA\n  [220,]   220        NA\n  [221,]   221        NA\n  [222,]   222        NA\n  [223,]",
        "   223        NA\n  [224,]   224        NA\n  [225,]   225        NA\n  [226,]   226        NA\n  [227,]   227        NA\n  [228,]   228        NA\n  [229,]   229        NA\n  [230,]   230        NA\n  [231,]   231        NA\n  [232,]   232        NA\n  [233,]   233        NA\n  [234,]   234        NA\n  [235,]   235        NA\n  [236,]   236        NA\n  [237,]   237        NA\n  [238,]   238        NA\n  [239,]   239        NA\n  [240,]   240        NA\n  [241,]   241        NA\n  [242,]   242        NA\n  [243,]   243        NA",
        "\n  [244,]   244        NA\n  [245,]   245        NA\n  [246,]   246        NA\n  [247,]   247        NA\n  [248,]   248        NA\n  [249,]   249        NA\n  [250,]   250        NA\n  [251,]   251        NA\n  [252,]   252        NA\n  [253,]   253        NA\n  [254,]   254        NA\n  [255,]   255        NA\n  [256,]   256        NA\n  [257,]   257        NA\n  [258,]   258        NA\n  [259,]   259        NA\n  [260,]   260        NA\n  [261,]   261        NA\n  [262,]   262        NA\n  [263,]   263        NA\n  [264,]   264",
        "        NA\n  [265,]   265        NA\n  [266,]   266        NA\n  [267,]   267        NA\n  [268,]   268        NA\n  [269,]   269        NA\n  [270,]   270        NA\n  [271,]   271        NA\n  [272,]   272        NA\n  [273,]   273        NA\n  [274,]   274        NA\n  [275,]   275        NA\n  [276,]   276        NA\n  [277,]   277        NA\n  [278,]   278        NA\n  [279,]   279        NA\n  [280,]   280        NA\n  [281,]   281        NA\n  [282,]   282        NA\n  [283,]   283        NA\n  [284,]   284        NA\n  [285,]",
        "   285        NA\n  [286,]   286        NA\n  [287,]   287        NA\n  [288,]   288        NA\n  [289,]   289        NA\n  [290,]   290        NA\n  [291,]   291        NA\n  [292,]   292        NA\n  [293,]   293        NA\n  [294,]   294        NA\n  [295,]   295        NA\n  [296,]   296        NA\n  [297,]   297        NA\n  [298,]   298        NA\n  [299,]   299        NA\n  [300,]   300        NA\n  [301,]   301        NA\n  [302,]   302        NA\n  [303,]   303        NA\n  [304,]   304        NA\n  [305,]   305        NA",
        "\n  [306,]   306        NA\n  [307,]   307        NA\n  [308,]   308        NA\n  [309,]   309        NA\n  [310,]   310        NA\n  [311,]   311        NA\n  [312,]   312        NA\n  [313,]   313        NA\n  [314,]   314        NA\n  [315,]   315        NA\n  [316,]   316        NA\n  [317,]   317        NA\n  [318,]   318        NA\n  [319,]   319        NA\n  [320,]   320        NA\n  [321,]   321        NA\n  [322,]   322        NA\n  [323,]   323        NA\n  [324,]   324        NA\n  [325,]   325        NA\n  [326,]   326",
        "        NA\n  [327,]   327        NA\n  [328,]   328        NA\n  [329,]   329        NA\n  [330,]   330        NA\n  [331,]   331        NA\n  [332,]   332        NA\n  [333,]   333        NA\n  [334,]   334        NA\n  [335,]   335        NA\n  [336,]   336        NA\n  [337,]   337        NA\n  [338,]   338        NA\n  [339,]   339        NA\n  [340,]   340        NA\n  [341,]   341        NA\n  [342,]   342        NA\n  [343,]   343        NA\n  [344,]   344        NA\n  [345,]   345        NA\n  [346,]   346        NA\n  [347,]",
        "   347        NA\n  [348,]   348        NA\n  [349,]   349        NA\n  [350,]   350        NA\n  [351,]   351        NA\n  [352,]   352        NA\n  [353,]   353        NA\n  [354,]   354        NA\n  [355,]   355        NA\n  [356,]   356        NA\n  [357,]   357        NA\n  [358,]   358        NA\n  [359,]   359        NA\n  [360,]   360        NA\n  [361,]   361        NA\n  [362,]   362        NA\n  [363,]   363        NA\n  [364,]   364        NA\n  [365,]   365        NA\n  [366,]   366        NA\n  [367,]   367        NA",
        "\n  [368,]   368        NA\n  [369,]   369        NA\n  [370,]   370        NA\n  [371,]   371        NA\n  [372,]   372        NA\n  [373,]   373        NA\n  [374,]   374        NA\n  [375,]   375        NA\n  [376,]   376        NA\n  [377,]   377        NA\n  [378,]   378        NA\n  [379,]   379        NA\n  [380,]   380        NA\n  [381,]   381        NA\n  [382,]   382        NA\n  [383,]   383        NA\n  [384,]   384        NA\n  [385,]   385        NA\n  [386,]   386        NA\n  [387,]   387        NA\n  [388,]   388",
        "        NA\n  [389,]   389        NA\n  [390,]   390        NA\n  [391,]   391        NA\n  [392,]   392        NA\n  [393,]   393        NA\n  [394,]   394        NA\n  [395,]   395        NA\n  [396,]   396        NA\n  [397,]   397        NA\n  [398,]   398        NA\n  [399,]   399        NA\n  [400,]   400        NA\n  [401,]   401        NA\n  [402,]   402        NA\n  [403,]   403        NA\n  [404,]   404        NA\n  [405,]   405        NA\n  [406,]   406        NA\n  [407,]   407        NA\n  [408,]   408        NA\n  [409,]",
        "   409        NA\n  [410,]   410        NA\n  [411,]   411        NA\n  [412,]   412        NA\n  [413,]   413        NA\n  [414,]   414        NA\n  [415,]   415        NA\n  [416,]   416        NA\n  [417,]   417        NA\n  [418,]   418        NA\n  [419,]   419        NA\n  [420,]   420        NA\n  [421,]   421        NA\n  [422,]   422        NA\n  [423,]   423        NA\n  [424,]   424        NA\n  [425,]   425        NA\n  [426,]   426        NA\n  [427,]   427        NA\n  [428,]   428        NA\n  [429,]   429        NA",
        "\n  [430,]   430        NA\n  [431,]   431        NA\n  [432,]   432        NA\n  [433,]   433        NA\n  [434,]   434        NA\n  [435,]   435        NA\n  [436,]   436        NA\n  [437,]   437        NA\n  [438,]   438        NA\n  [439,]   439        NA\n  [440,]   440        NA\n  [441,]   441        NA\n  [442,]   442        NA\n  [443,]   443        NA\n  [444,]   444        NA\n  [445,]   445        NA\n  [446,]   446        NA\n  [447,]   447        NA\n  [448,]   448        NA\n  [449,]   449        NA\n  [450,]   450",
        "        NA\n  [451,]   451        NA\n  [452,]   452        NA\n  [453,]   453        NA\n  [454,]   454        NA\n  [455,]   455        NA\n  [456,]   456        NA\n  [457,]   457        NA\n  [458,]   458        NA\n  [459,]   459        NA\n  [460,]   460        NA\n  [461,]   461        NA\n  [462,]   462        NA\n  [463,]   463        NA\n  [464,]   464        NA\n  [465,]   465        NA\n  [466,]   466        NA\n  [467,]   467        NA\n  [468,]   468        NA\n  [469,]   469        NA\n  [470,]   470        NA\n  [471,]",
        "   471        NA\n  [472,]   472        NA\n  [473,]   473        NA\n  [474,]   474        NA\n  [475,]   475        NA\n  [476,]   476        NA\n  [477,]   477        NA\n  [478,]   478        NA\n  [479,]   479        NA\n  [480,]   480        NA\n  [481,]   481        NA\n  [482,]   482        NA\n  [483,]   483        NA\n  [484,]   484        NA\n  [485,]   485        NA\n  [486,]   486        NA\n  [487,]   487        NA\n  [488,]   488        NA\n  [489,]   489        NA\n  [490,]   490        NA\n  [491,]   491        NA",
        "\n  [492,]   492        NA\n  [493,]   493        NA\n  [494,]   494        NA\n  [495,]   495        NA\n  [496,]   496        NA\n  [497,]   497        NA\n  [498,]   498        NA\n  [499,]   499        NA\n  [500,]   500        NA\n [ reached getOption(\"max.print\") -- omitted 9500 rows ]\n\n",
        "> ",
        "#d is the censoring indicator (0=right censored, 1=event at time,",
        "> ",
        "# 2=left censored, 3=interval censored)",
        "> ",
        "#wt are the weights for the observations",
        "> ",
        "#dist: either the \"weibull\", \"lognormal\", or \"gaussian\" distribution",
        "> ",
        "#n is the number of components",
        "> ",
        "#cluster: start with random initialization of posterior probabilities (=NULL), or",
        "> ",
        "# a matrix with n columns of initial posterior probabilities for the observations",
        "> ",
        "#classify: \"EM\", \"CEM\", or \"SEM\" strategy",
        "> ",
        "#maxiter is the maximum number of iterations",
        "> ",
        "#tol is the convergence criterion",
        "> ",
        "gmm_int_cen$iterations",
        "[1] 2\n",
        "> ",
        "gmm_int_cen$prior",
        "[1] 0.4969141 0.5030859\n",
        "> ",
        "gmm_int_cen$loglik",
        "[1] -5801.351\n",
        "> ",
        "gmm_int_cen$prior",
        "[1] 0.4969141 0.5030859\n",
        "> ",
        "gmm_int_cen$standardError",
        "             mu log(sigma)\n[1,] 0.04924134 0.02317785\n[2,] 0.04926742 0.02302410\n",
        "> ",
        "#d is the censoring indicator (0=right censored, 1=event at time,",
        "> ",
        "# 2=left censored, 3=interval censored)",
        "> ",
        "#wt are the weights for the observations",
        "> ",
        "#dist: either the \"weibull\", \"lognormal\", or \"gaussian\" distribution",
        "> ",
        "#n is the number of components",
        "> ",
        "#cluster: start with random initialization of posterior probabilities (=NULL), or",
        "> ",
        "# a matrix with n columns of initial posterior probabilities for the observations",
        "> ",
        "#classify: \"EM\", \"CEM\", or \"SEM\" strategy",
        "> ",
        "#maxiter is the maximum number of iterations",
        "> ",
        "#tol is the convergence criterion",
        "> ",
        "gmm_int_cen$components",
        "             mu    sigma\n[1,] -0.3123482 1.537399\n[2,] -0.2357960 1.547973\n",
        "> ",
        "gmm_int_cen$prior",
        "[1] 0.4969141 0.5030859\n",
        "> ",
        "gmm_int_cen$loglik",
        "[1] -5801.351\n",
        "> ",
        "gmm_int_cen$iterations",
        "[1] 2\n",
        "> ",
        "gmm_int_cen$standardError",
        "             mu log(sigma)\n[1,] 0.04924134 0.02317785\n[2,] 0.04926742 0.02302410\n",
        "> ",
        "plot(x = gmm_int_cen$likelihood_documentation_gmm[,1], y= gmm_int_cen$likelihood_documentation_gmm[,2], type = \"l\")",
        "> ",
        "hist(data.sim$observed_value)",
        "> ",
        "library(ggplot2)",
        "> ",
        "data.sim %>% ",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value))",
        "`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n",
        "> ",
        "data.sim %>% ",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value), binwidth = 1)",
        "> ",
        "?geom_histogram",
        "> ",
        "data.sim %>% ",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value), binwidth = 1, boundary = 0)",
        "> ",
        "data.sim %>% ",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, color = indicator), binwidth = 1, boundary = 0)",
        "> ",
        "data.sim %>% ",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, color = factor(indicator)), binwidth = 1, boundary = 0)",
        "> ",
        "data.sim %>% ",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, fill = factor(indicator)), binwidth = 1, boundary = 0)",
        "> ",
        "data.sim %>% ",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, fill = factor(indicator)), binwidth = 1, boundary = 0, color = black)",
        "Error in layer(data = data, mapping = mapping, stat = stat, geom = GeomBar,  : \n  object 'black' not found\n",
        "> ",
        "data.sim %>% ",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, fill = factor(indicator)), binwidth = 1, boundary = 0, color = \"black\")",
        "> ",
        "pi1 = function(t) {z <- 0.6",
        "+ ",
        "c(\"1\" = z, \"2\" = 1- z)}",
        "> ",
        "`E[X|T,C]` = function(t, c)",
        "+ ",
        "{",
        "+ ",
        "  case_when(",
        "+ ",
        "    c == \"1\" ~ 0 + 0 * t,",
        "+ ",
        "    c == \"2\" ~ 2 + 0 * t,",
        "+ ",
        "    TRUE ~ NaN",
        "+ ",
        "  )",
        "+ ",
        "}",
        "> ",
        "t_dist1 = function(n){runif(n, min = 0, max = 1)}",
        "> ",
        "sd_vector = c(\"1\" = 1, \"2\" = 1)",
        "> ",
        "low_con = 2^-4",
        "> ",
        "high_con = 2^4",
        "> ",
        "##Covariate inputs--------------------",
        "> ",
        "covariate_effect_vector <- c(0 #0 at start is intercept, then add in the desired coefficients for the covariates",
        "+ ",
        ")",
        "> ",
        "covariate_list <-",
        "+ ",
        "  NULL",
        "> ",
        "covariate_names <- NULL",
        "> ",
        "data.sim <- simulate_mics(",
        "+ ",
        "  n = n,",
        "+ ",
        "  t_dist = t_dist1,",
        "+ ",
        "  pi = pi1,",
        "+ ",
        "  `E[X|T,C]` = `E[X|T,C]`,",
        "+ ",
        "  sd_vector = sd_vector,",
        "+ ",
        "  covariate_list = covariate_list,",
        "+ ",
        "  covariate_effect_vector = covariate_effect_vector,",
        "+ ",
        "  low_con = low_con,",
        "+ ",
        "  high_con = high_con)",
        "> ",
        "data.sim %>% ",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, fill = factor(indicator)), binwidth = 1, boundary = 0, color = \"black\")",
        "> ",
        "table(data.sim$indicator == 2)",
        "\nFALSE \n 2000 \n",
        "> ",
        "table(data.sim$left_bound)",
        "\n0.0625  0.125   0.25    0.5      1      2      4      8     16 \n     3     27    146    444    486    454    308    121     11 \n",
        "> ",
        "table(ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ))",
        "\n0.0625  0.125   0.25    0.5      1      2      4      8     16 \n     3     27    146    444    486    454    308    121     11 \n",
        "> ",
        "gmm_int_cen <- mixcensoredInt(y1 = ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ),  #format would be wrong for this, need a conversion factor if using this notation",
        "+ ",
        "               y2 = data.sim$right_bound,",
        "+ ",
        "               d = data.sim$indicator,",
        "+ ",
        "               wt=rep(1, length(data.sim$observed_value)),",
        "+ ",
        "               dist=\"lognormal\",",
        "+ ",
        "               n = 2,",
        "+ ",
        "               cluster=NULL,",
        "+ ",
        "               classify=\"EM\",",
        "+ ",
        "               maxiter=10000, tol=1e-6)",
        "> ",
        "#d is the censoring indicator (0=right censored, 1=event at time,",
        "> ",
        "# 2=left censored, 3=interval censored)",
        "> ",
        "#wt are the weights for the observations",
        "> ",
        "#dist: either the \"weibull\", \"lognormal\", or \"gaussian\" distribution",
        "> ",
        "#n is the number of components",
        "> ",
        "#cluster: start with random initialization of posterior probabilities (=NULL), or",
        "> ",
        "# a matrix with n columns of initial posterior probabilities for the observations",
        "> ",
        "#classify: \"EM\", \"CEM\", or \"SEM\" strategy",
        "> ",
        "#maxiter is the maximum number of iterations",
        "> ",
        "#tol is the convergence criterion",
        "> ",
        "gmm_int_cen$components",
        "            mu     sigma\n[1,] 0.5870986 0.9729956\n[2,] 0.5570840 0.9639573\n",
        "> ",
        "gmm_int_cen$prior",
        "[1] 0.4863023 0.5136977\n",
        "> ",
        "gmm_int_cen$loglik",
        "[1] -4929.692\n",
        "> ",
        "gmm_int_cen$iterations",
        "[1] 6\n",
        "> ",
        "gmm_int_cen$standardError",
        "             mu log(sigma)\n[1,] 0.03185837 0.02371856\n[2,] 0.03071995 0.02308249\n",
        "> ",
        "`E[X|T,C]` = function(t, c)",
        "+ ",
        "{",
        "+ ",
        "  case_when(",
        "+ ",
        "    c == \"1\" ~ 0 + 0 * t,",
        "+ ",
        "    c == \"2\" ~ 4 + 0 * t,",
        "+ ",
        "    TRUE ~ NaN",
        "+ ",
        "  )",
        "+ ",
        "}",
        "> ",
        "t_dist1 = function(n){runif(n, min = 0, max = 1)}",
        "> ",
        "sd_vector = c(\"1\" = 1, \"2\" = 1)",
        "> ",
        "low_con = 2^-4",
        "> ",
        "high_con = 2^4",
        "> ",
        "##Covariate inputs--------------------",
        "> ",
        "covariate_effect_vector <- c(0 #0 at start is intercept, then add in the desired coefficients for the covariates",
        "+ ",
        ")",
        "> ",
        "covariate_list <-",
        "+ ",
        "  NULL",
        "> ",
        "covariate_names <- NULL",
        "> ",
        "data.sim <- simulate_mics(",
        "+ ",
        "  n = n,",
        "+ ",
        "  t_dist = t_dist1,",
        "+ ",
        "  pi = pi1,",
        "+ ",
        "  `E[X|T,C]` = `E[X|T,C]`,",
        "+ ",
        "  sd_vector = sd_vector,",
        "+ ",
        "  covariate_list = covariate_list,",
        "+ ",
        "  covariate_effect_vector = covariate_effect_vector,",
        "+ ",
        "  low_con = low_con,",
        "+ ",
        "  high_con = high_con)",
        "> ",
        "data.sim %>% ",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, fill = factor(indicator)), binwidth = 1, boundary = 0, color = \"black\")",
        "> ",
        "table(data.sim$indicator == 2)",
        "\nFALSE \n 2000 \n",
        "> ",
        "table(data.sim$left_bound)",
        "\n0.0625  0.125   0.25    0.5      1      2      4      8     16 \n     2     26    171    434    402    169    116    300    380 \n",
        "> ",
        "table(ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ))",
        "\n0.0625  0.125   0.25    0.5      1      2      4      8     16 \n     2     26    171    434    402    169    116    300    380 \n",
        "> ",
        "gmm_int_cen <- mixcensoredInt(y1 = ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ),  #format would be wrong for this, need a conversion factor if using this notation",
        "+ ",
        "               y2 = data.sim$right_bound,",
        "+ ",
        "               d = data.sim$indicator,",
        "+ ",
        "               wt=rep(1, length(data.sim$observed_value)),",
        "+ ",
        "               dist=\"lognormal\",",
        "+ ",
        "               n = 2,",
        "+ ",
        "               cluster=NULL,",
        "+ ",
        "               classify=\"EM\",",
        "+ ",
        "               maxiter=10000, tol=1e-6)",
        "> ",
        "#d is the censoring indicator (0=right censored, 1=event at time,",
        "> ",
        "# 2=left censored, 3=interval censored)",
        "> ",
        "#wt are the weights for the observations",
        "> ",
        "#dist: either the \"weibull\", \"lognormal\", or \"gaussian\" distribution",
        "> ",
        "#n is the number of components",
        "> ",
        "#cluster: start with random initialization of posterior probabilities (=NULL), or",
        "> ",
        "# a matrix with n columns of initial posterior probabilities for the observations",
        "> ",
        "#classify: \"EM\", \"CEM\", or \"SEM\" strategy",
        "> ",
        "#maxiter is the maximum number of iterations",
        "> ",
        "#tol is the convergence criterion",
        "> ",
        "gmm_int_cen$components",
        "              mu     sigma\n[1,] -0.02413923 0.6870607\n[2,]  2.75259972 0.6012144\n",
        "> ",
        "gmm_int_cen$prior",
        "[1] 0.6095401 0.3904599\n",
        "> ",
        "gmm_int_cen$loglik",
        "[1] -3907.31\n",
        "> ",
        "gmm_int_cen$iterations",
        "[1] 66\n",
        "> ",
        "gmm_int_cen$standardError",
        "             mu log(sigma)\n[1,] 0.02049534 0.02192903\n[2,] 0.02645748 0.04253117\n",
        "> ",
        "exp(0.68)",
        "[1] 1.973878\n",
        "> ",
        "0.68/log(2)",
        "[1] 0.9810326\n",
        "> ",
        "2.75/lo(2)",
        "Error in lo(2) : could not find function \"lo\"\n",
        "> ",
        "2.75/log(2)",
        "[1] 3.967411\n",
        "> ",
        "gmm_int_cen$prior",
        "[1] 0.6095401 0.3904599\n",
        "> ",
        "gmm_int_cen$loglik",
        "[1] -3907.31\n",
        "> ",
        "gmm_int_cen$iterations",
        "[1] 66\n",
        "> ",
        "gmm_int_cen$standardError",
        "             mu log(sigma)\n[1,] 0.02049534 0.02192903\n[2,] 0.02645748 0.04253117\n",
        "> ",
        "mm_int_cen <- mixcensoredInt(y1 = ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ),  #format would be wrong for this, need a conversion factor if using this notation",
        "+ ",
        "               y2 = data.sim$right_bound,",
        "+ ",
        "               d = data.sim$indicator,",
        "+ ",
        "               wt=rep(1, length(data.sim$observed_value)),",
        "+ ",
        "               dist=\"lognormal\",",
        "+ ",
        "               n = 2,",
        "+ ",
        "               cluster=NULL,",
        "+ ",
        "               classify=\"EM\",",
        "+ ",
        "               maxiter=10000, tol=1e-6)",
        "> ",
        "gmm_int_cen <- mixcensoredInt(y1 = ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ),  #format would be wrong for this, need a conversion factor if using this notation",
        "+ ",
        "               y2 = data.sim$right_bound,",
        "+ ",
        "               d = data.sim$indicator,",
        "+ ",
        "               wt=rep(1, length(data.sim$observed_value)),",
        "+ ",
        "               dist=\"lognormal\",",
        "+ ",
        "               n = 2,",
        "+ ",
        "               cluster=NULL,",
        "+ ",
        "               classify=\"EM\",",
        "+ ",
        "               maxiter=10000, tol=1e-6)",
        "> ",
        "#d is the censoring indicator (0=right censored, 1=event at time,",
        "> ",
        "# 2=left censored, 3=interval censored)",
        "> ",
        "#wt are the weights for the observations",
        "> ",
        "#dist: either the \"weibull\", \"lognormal\", or \"gaussian\" distribution",
        "> ",
        "#n is the number of components",
        "> ",
        "#cluster: start with random initialization of posterior probabilities (=NULL), or",
        "> ",
        "# a matrix with n columns of initial posterior probabilities for the observations",
        "> ",
        "#classify: \"EM\", \"CEM\", or \"SEM\" strategy",
        "> ",
        "#maxiter is the maximum number of iterations",
        "> ",
        "#tol is the convergence criterion",
        "> ",
        "gmm_int_cen$components  ###Divide by log2 to get correct things here",
        "              mu     sigma\n[1,] -0.02413717 0.6870626\n[2,]  2.75260115 0.6012097\n",
        "> ",
        "gmm_int_cen$prior",
        "[1] 0.6095409 0.3904591\n",
        "> ",
        "gmm_int_cen$loglik",
        "[1] -3907.309\n",
        "> ",
        "gmm_int_cen$iterations",
        "[1] 65\n",
        "> ",
        "gmm_int_cen$standardError",
        "             mu log(sigma)\n[1,] 0.02049537 0.02192901\n[2,] 0.02645734 0.04253133\n",
        "> ",
        "2.75/log(2)",
        "[1] 3.967411\n",
        "> ",
        ".6871/log(2)",
        "[1] 0.9912758\n",
        "> ",
        "data.sim %>%",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, fill = factor(indicator)), binwidth = 1, boundary = 0, color = \"black\")",
        "> ",
        "data.sim %>%",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, fill = factor(indicator)), binwidth = 1, boundary = 0, color = \"black\") +",
        "+ ",
        "  facet_wrap(~indicator)",
        "> ",
        "data.sim %>%",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, fill = factor(indicator)), binwidth = 1, boundary = 0, color = \"black\") +",
        "+ ",
        "  facet_wrap(~comp)",
        "> ",
        "`E[X|T,C]` = function(t, c)",
        "+ ",
        "{",
        "+ ",
        "  case_when(",
        "+ ",
        "    c == \"1\" ~ -2 + 0 * t,",
        "+ ",
        "    c == \"2\" ~ 5 + 0 * t,",
        "+ ",
        "    TRUE ~ NaN",
        "+ ",
        "  )",
        "+ ",
        "}",
        "> ",
        "t_dist1 = function(n){runif(n, min = 0, max = 1)}",
        "> ",
        "sd_vector = c(\"1\" = 1, \"2\" = 1)",
        "> ",
        "low_con = 2^-4",
        "> ",
        "high_con = 2^4",
        "> ",
        "##Covariate inputs--------------------",
        "> ",
        "covariate_effect_vector <- c(0 #0 at start is intercept, then add in the desired coefficients for the covariates",
        "+ ",
        ")",
        "> ",
        "covariate_list <-",
        "+ ",
        "  NULL",
        "> ",
        "covariate_names <- NULL",
        "> ",
        "data.sim <- simulate_mics(",
        "+ ",
        "  n = n,",
        "+ ",
        "  t_dist = t_dist1,",
        "+ ",
        "  pi = pi1,",
        "+ ",
        "  `E[X|T,C]` = `E[X|T,C]`,",
        "+ ",
        "  sd_vector = sd_vector,",
        "+ ",
        "  covariate_list = covariate_list,",
        "+ ",
        "  covariate_effect_vector = covariate_effect_vector,",
        "+ ",
        "  low_con = low_con,",
        "+ ",
        "  high_con = high_con)",
        "> ",
        "data.sim %>%",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, fill = factor(indicator)), binwidth = 1, boundary = 0, color = \"black\") +",
        "+ ",
        "  facet_wrap(~comp)",
        "> ",
        "table(data.sim$indicator == 2)",
        "\nFALSE  TRUE \n 1972    28 \n",
        "> ",
        "table(data.sim$left_bound)",
        "\n     0 0.0625  0.125   0.25    0.5      1      2      4      8     16 \n    28    174    408    396    175     26      1     16    108    668 \n",
        "> ",
        "table(ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ))",
        "\n0.0625  0.125   0.25    0.5      1      2      4      8     16 \n   202    408    396    175     26      1     16    108    668 \n",
        "> ",
        "data.sim %>%",
        "+ ",
        "  ggplot() +",
        "+ ",
        "  geom_histogram(aes(x = observed_value, fill = factor(indicator)), binwidth = 1, boundary = 0, color = \"black\")",
        "> ",
        "gmm_int_cen <- mixcensoredInt(y1 = ifelse(data.sim$indicator == 2, data.sim$right_bound, data.sim$left_bound ),  #format would be wrong for this, need a conversion factor if using this notation",
        "+ ",
        "               y2 = data.sim$right_bound,",
        "+ ",
        "               d = data.sim$indicator,",
        "+ ",
        "               wt=rep(1, length(data.sim$observed_value)),",
        "+ ",
        "               dist=\"lognormal\",",
        "+ ",
        "               n = 2,",
        "+ ",
        "               cluster=NULL,",
        "+ ",
        "               classify=\"EM\",",
        "+ ",
        "               maxiter=10000, tol=1e-6)",
        "> ",
        "#d is the censoring indicator (0=right censored, 1=event at time,",
        "> ",
        "# 2=left censored, 3=interval censored)",
        "> ",
        "#wt are the weights for the observations",
        "> ",
        "#dist: either the \"weibull\", \"lognormal\", or \"gaussian\" distribution",
        "> ",
        "#n is the number of components",
        "> ",
        "#cluster: start with random initialization of posterior probabilities (=NULL), or",
        "> ",
        "# a matrix with n columns of initial posterior probabilities for the observations",
        "> ",
        "#classify: \"EM\", \"CEM\", or \"SEM\" strategy",
        "> ",
        "#maxiter is the maximum number of iterations",
        "> ",
        "#tol is the convergence criterion",
        "> ",
        "gmm_int_cen$components  ###Divide by log2 to get correct things here",
        "            mu     sigma\n[1,]  3.433722 0.6567268\n[2,] -1.391261 0.7033309\n",
        "> ",
        "gmm_int_cen$prior",
        "[1] 0.3961225 0.6038775\n",
        "> ",
        "gmm_int_cen$loglik",
        "[1] -3508.46\n",
        "> ",
        "gmm_int_cen$iterations",
        "[1] 23\n",
        "> ",
        "gmm_int_cen$standardError",
        "             mu log(sigma)\n[1,] 0.07439158 0.08875915\n[2,] 0.02105620 0.02223274\n",
        "> ",
        "3.433/log(2)",
        "[1] 4.952772\n",
        "> ",
        "-1.39/log(2)",
        "[1] -2.005346\n\nRestarting R session...\n\n"
    ]
}