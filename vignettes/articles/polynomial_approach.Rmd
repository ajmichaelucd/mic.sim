---
title: "polynomial_approach"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{polynomial_approach}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(mic.sim)
library(mgcv)
library(dplyr)
library(ggplot2)
library(ggnewscale)
library(survival)
```

```{r}
set.seed(1)
n = 300
ncomp = 2
pi = function(t) {
  z <- 0.07 + 0.03 * t - 0.00045 * t^2
  #z <- (1+ exp(-m))^-1 #if exp(m) gets large, it won't add the 1 so we write like this
  tibble("1" = 1 - z, "2" = z)
}
`E[X|T,C]` = function(t, c)
{
  case_when(
    c == "1" ~ -4.0 + (0.24 * t) - (0.0055 * t^2),
    c == "2" ~ 3 + 0.001 * t,
    TRUE ~ NaN
  )
}
t_dist = function(n){runif(n, min = 0, max = 16)}
attr(t_dist, "min") = 0
attr(t_dist, "max") = 16
sd_vector = c("1" = 1, "2" = 1.05)
low_con = -3
high_con = 3
scale = "log"
example_data = simulate_mics(n = n, t_dist = t_dist, pi = pi, `E[X|T,C]` = `E[X|T,C]`, sd_vector = sd_vector, covariate_list = NULL, covariate_effect_vector = c(0), low_con = low_con, high_con = high_con, scale = "log") %>% suppressMessages()

example_data %>% 
  mutate(verbose_comp = case_when(
    comp == 1 ~ "Component 1",
    TRUE ~ "Component 2"
  )) %>% 
  ggplot() +
  geom_segment(aes(x = t, xend = t, y = left_bound, yend = right_bound, color = verbose_comp), data = (. %>% filter(left_bound != -Inf & right_bound != Inf)), alpha = 0.3) +
  geom_segment(aes(x = t, xend = t, y = right_bound, yend = left_bound, color = verbose_comp), data = (. %>% filter(left_bound == -Inf) %>% mutate(left_bound = low_con - 2)), arrow = arrow(length = unit(0.03, "npc")), alpha = 0.3) +
  geom_segment(aes(x = t, xend = t, y = left_bound, yend = right_bound, color = verbose_comp), data = (. %>% filter(right_bound == Inf) %>% mutate(right_bound = high_con + 2)), arrow = arrow(length = unit(0.03, "npc")), alpha = 0.3) +
  geom_point(aes(x = t, y = left_bound, color = verbose_comp), data = . %>% filter(left_bound != -Inf), alpha = 0.3) +
  geom_point(aes(x = t, y = right_bound, color = verbose_comp), data = . %>% filter(right_bound != Inf), alpha = 0.3) +
  geom_function(fun = function(t){`E[X|T,C]`(t, c = "1")}, aes(color = "Component 1 Mean")) +
  geom_function(fun = function(t){`E[X|T,C]`(t, c = "2")}, aes(color = "Component 2 Mean")) +
  xlim(attr(t_dist, "min") ,attr(t_dist, "max")) +
  ylim(low_con - 2, high_con + 2)
```

```{r}
polynomial_output = fit_polynomial_EM(
  max_degree = 8,
  visible_data = example_data,
  nfolds = 10,
  non_linear_term = "t",
  covariates = NULL,
  pi_formula = c == "2" ~ s(t),
  max_it = 3000,
  ncomp = 2,
  tol_ll = 1e-6,
  pi_link = "logit",
  verbose = 1,
  model_coefficient_tolerance = 0.00001,
  initial_weighting = 8,
  sd_initial = 0.2
)

plot_likelihood(polynomial_output$likelihood)

plot_fm(polynomial_output, "cv_selected")
```

```{r}
random_seeds_vector = sample(x = 1:1000000, size = 100, replace = FALSE)
pspline_output = EM_fm_surv_batch_run(
  random_seeds_vector,
  example_data,
  mu_formula = Surv(time = left_bound,
                    time2 = right_bound,
                    type = "interval2") ~ pspline(t, df = 0, caic = TRUE),
  pi_formula = c == "2" ~ s(t),
  max_it = 500,
  ncomp = 2,
  tol_ll = 1e-6,
  pi_link = "logit",
  verbose = 1,
  initial_weighting = 7,
  model_coefficient_tolerance = 0.00001,
  maxiter_survreg = 30,
  sd_initial = 0.2,
  randomize = "all"
)


get_like = function(grid_output){
  grid_output$final_like %>% return()
}

summary = map(pspline_output, get_like) %>% data.table::rbindlist(.) %>% tibble %>% arrange(desc(likelihood))
plot_likelihood(pspline_output[[summary %>% head(1) %>% pull(iter)]]$output$likelihood)
plot_fm(pspline_output[[(summary %>% head(1) %>% pull(iter))]]$output, "top iter")
```

